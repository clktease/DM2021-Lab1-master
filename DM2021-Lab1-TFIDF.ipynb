{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53eda5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "['Good case, Excellent value.', 1]\n",
      "1000\n",
      "['Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.  ', 0]\n",
      "1000\n",
      "['Crust is not good.', 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#read txt\n",
    "amazon = open('C:/Users/james/sentiment labelled sentences/amazon_cells_labelled.txt',\"r\",encoding=\"utf-8\")\n",
    "imdb = open('C:/Users/james/sentiment labelled sentences/imdb_labelled.txt',\"r\",encoding=\"utf-8\")\n",
    "yelp = open('C:/Users/james/sentiment labelled sentences/yelp_labelled.txt',\"r\",encoding=\"utf-8\")\n",
    "\n",
    "data1 = list(amazon)\n",
    "data2 = (list(imdb))\n",
    "data3 = (list(yelp))\n",
    "doc1 = []\n",
    "doc2 = []\n",
    "doc3 = []\n",
    "#convert to list\n",
    "for i in data1:\n",
    "    x = i.split('\\t')\n",
    "    k = x[1].split('\\n')    \n",
    "    doc1.append([x[0],int(k[0])])\n",
    "for i in data2:\n",
    "    x = i.split('\\t')\n",
    "    k = x[1].split('\\n')    \n",
    "    doc2.append([x[0],int(k[0])])\n",
    "for i in data3:\n",
    "    x = i.split('\\t')\n",
    "    k = x[1].split('\\n')    \n",
    "    doc3.append([x[0],int(k[0])])   \n",
    "print(len(data1))\n",
    "print(doc1[1])\n",
    "print(len(data2))\n",
    "print(doc2[1])\n",
    "print(len(data3))\n",
    "print(doc3[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "137da64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              sentence score\n",
      "0    So there is no way for me to plug it in here i...     0\n",
      "1                          Good case, Excellent value.     1\n",
      "2                               Great for the jawbone.     1\n",
      "3    Tied to charger for conversations lasting more...     0\n",
      "4                                    The mic is great.     1\n",
      "..                                                 ...   ...\n",
      "995  The screen does get smudged easily because it ...     0\n",
      "996  What a piece of junk.. I lose more calls on th...     0\n",
      "997                       Item Does Not Match Picture.     0\n",
      "998  The only thing that disappoint me is the infra...     0\n",
      "999  You can not answer calls with the unit, never ...     0\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "                                              sentence score\n",
      "0    A very, very, very slow-moving, aimless movie ...     0\n",
      "1    Not sure who was more lost - the flat characte...     0\n",
      "2    Attempting artiness with black & white and cle...     0\n",
      "3         Very little music or anything to speak of.       0\n",
      "4    The best scene in the movie was when Gerardo i...     1\n",
      "..                                                 ...   ...\n",
      "995  I just got bored watching Jessice Lange take h...     0\n",
      "996  Unfortunately, any virtue in this film's produ...     0\n",
      "997                   In a word, it is embarrassing.       0\n",
      "998                               Exceptionally bad!       0\n",
      "999  All in all its an insult to one's intelligence...     0\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "                                              sentence score\n",
      "0                             Wow... Loved this place.     1\n",
      "1                                   Crust is not good.     0\n",
      "2            Not tasty and the texture was just nasty.     0\n",
      "3    Stopped by during the late May bank holiday of...     1\n",
      "4    The selection on the menu was great and so wer...     1\n",
      "..                                                 ...   ...\n",
      "995  I think food should have flavor and texture an...     0\n",
      "996                           Appetite instantly gone.     0\n",
      "997  Overall I was not impressed and would not go b...     0\n",
      "998  The whole experience was underwhelming, and I ...     0\n",
      "999  Then, as if I hadn't wasted enough of my life ...     0\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import helpers.data_mining_helpers as dmh\n",
    "\n",
    "doc1 = np.array(doc1)\n",
    "df1 = pd.DataFrame({'sentence': doc1[:,0],\n",
    "                   'score': doc1[:,1],})\n",
    "doc2 = np.array(doc2)\n",
    "df2 = pd.DataFrame({'sentence': doc2[:,0],\n",
    "                   'score': doc2[:,1],})\n",
    "doc3 = np.array(doc3)\n",
    "df3 = pd.DataFrame({'sentence': doc3[:,0],\n",
    "                   'score': doc3[:,1],})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ba4f3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>15g</th>\n",
       "      <th>...</th>\n",
       "      <th>yukon</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yun</th>\n",
       "      <th>z</th>\n",
       "      <th>z500a</th>\n",
       "      <th>zero</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombiez</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 5206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  00   1  10  100  11  12  13  15  15g  ...  yukon  yum  yummy  yun  z  \\\n",
       "0  0   0   9   4    1   1   1   1   1    1  ...      0    0      0    0  0   \n",
       "1  2   1  13  34    2   1   3   2   2    0  ...      1    2      4    1  1   \n",
       "2  0   0   0   0    0   0   0   0   0    0  ...      0    0      0    0  0   \n",
       "\n",
       "   z500a  zero  zillion  zombie  zombiez  \n",
       "0      1     1        0       0        0  \n",
       "1      0     5        1       2        1  \n",
       "2      0     0        0       0        0  \n",
       "\n",
       "[3 rows x 5206 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "str1 = ''\n",
    "str2 = ''\n",
    "str3 = ''\n",
    "for i in range(1000):\n",
    "    str1 += doc1[i][0]\n",
    "for i in range(1000):\n",
    "    str2 += doc2[i][0]\n",
    "for i in range(1000):\n",
    "    str2 += doc3[i][0]\n",
    "\n",
    "\n",
    "\n",
    "#word frequency\n",
    "vectorizer = CountVectorizer(stop_words=None, token_pattern=\"(?u)\\\\b\\\\w+\\\\b\")\n",
    "X = vectorizer.fit_transform([str1,str2,str3])\n",
    "result1 = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d6009ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>15g</th>\n",
       "      <th>...</th>\n",
       "      <th>yukon</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yun</th>\n",
       "      <th>z</th>\n",
       "      <th>z500a</th>\n",
       "      <th>zero</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombiez</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>str1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008628</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str2</th>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.013759</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.000532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 5206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0        00         1        10       100        11        12  \\\n",
       "str1  0.000000  0.000000  0.008628  0.003835  0.000959  0.000959  0.000959   \n",
       "str2  0.001064  0.000532  0.005261  0.013759  0.000809  0.000405  0.001214   \n",
       "str3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            13        15       15g  ...     yukon       yum     yummy  \\\n",
       "str1  0.000959  0.000959  0.001261  ...  0.000000  0.000000  0.000000   \n",
       "str2  0.000809  0.000809  0.000000  ...  0.000532  0.001064  0.002128   \n",
       "str3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "           yun         z     z500a      zero   zillion    zombie   zombiez  \n",
       "str1  0.000000  0.000000  0.001261  0.000959  0.000000  0.000000  0.000000  \n",
       "str2  0.000532  0.000532  0.000000  0.002023  0.000532  0.001064  0.000532  \n",
       "str3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[3 rows x 5206 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TFIDF\n",
    "transformer = TfidfTransformer(smooth_idf=True)\n",
    "Z = transformer.fit_transform(X)\n",
    "result2 = pd.DataFrame(Z.toarray(),columns=vectorizer.get_feature_names(), index=['str1', 'str2', 'str3'])\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26d60120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5206)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = np.array(result1)\n",
    "r2 = np.array(result2)\n",
    "r1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3171a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40f261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
